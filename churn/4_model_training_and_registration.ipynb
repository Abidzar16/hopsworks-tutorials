{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12c2d93",
   "metadata": {},
   "source": [
    "## Model training and registration\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "- Register a model to the model registry.\n",
    "- Fetch the model from the model registry.\n",
    "\n",
    "This will introduce the `hsml` (**H**opsworks **M**achine **L**earning) library, which contains functionality to keep track of models and deploy them.\n",
    "\n",
    "*Note: you need to enable Serving to run this notebook. Go to the **old** Hopsworks UI, click on settings, and check the Serving box.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86096f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cceb37c",
   "metadata": {},
   "source": [
    "### Load Best Hyperparameters\n",
    "\n",
    "We will train a model using the best hyperparameters we found in the previous notebook.\n",
    "Recall that we saved these as a pickled dictionary that we uploaded to our cluster.\n",
    "If you don't have the file locally you can download it using the *hopsworks* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495ed114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632b792a51584f88ba4d3a6a28d8b25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=32.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/srv/hops/staging/private_dirs/d53098136e6355738677dfe1bd0cbac9320ccefcc3f6ed636b22171b31a72481/best_params.pickle'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "hopsworks_conn = hopsworks.connection()\n",
    "project = hopsworks_conn.get_project()\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = \"Resources/best_params.pickle\"\n",
    "dataset_api.download(uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50be8ff",
   "metadata": {},
   "source": [
    "Retrieve the best hyperparameters from this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0ba701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"best_params.pickle\", \"rb\") as f:\n",
    "    best_params = pickle.load(f)\n",
    "\n",
    "n_estimators = best_params[\"n_estimators\"]\n",
    "\n",
    "print(n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6207b600",
   "metadata": {},
   "source": [
    "### Load Training Data & Train Model\n",
    "\n",
    "Next, we'll train a model in the same way as the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5fec8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Training dataset splits were defined but no `train_split` (the name of the split that is going to be used for training) was provided. Setting this property to `train`. The statistics of this split will be used for transformation functions.\n",
      "FutureWarning: pyarrow.hdfs.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 0.09999999999999998, 1: 0.9},\n",
       "                   dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "                   l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                   penalty='l2', random_state=None, solver='liblinear',\n",
       "                   tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load data.\n",
    "feature_view = fs.get_feature_view(\"churn_feature_view\", 1)\n",
    "_, td_df = feature_view.get_training_dataset_splits({'train': 70, 'validation': 30}, start_time=None, end_time=None, version = 1)\n",
    "\n",
    "X_train = td_df[\"train\"]\n",
    "X_val = td_df['validation']\n",
    "\n",
    "# Separate target feature from input features.\n",
    "target = target = feature_view.label[0]  \n",
    "y_train = X_train.pop(target)\n",
    "y_val = X_val.pop(target)\n",
    "\n",
    "# Train model.\n",
    "pos_class_weight = 0.9\n",
    "clf = LogisticRegression(class_weight={0: 1.0 - pos_class_weight, 1: pos_class_weight}, solver='liblinear')\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176002c",
   "metadata": {},
   "source": [
    "We will also compute some evaluation metrics, which we will register together with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec07be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.49      0.65      1556\n",
      "           1       0.39      0.95      0.55       533\n",
      "\n",
      "    accuracy                           0.61      2089\n",
      "   macro avg       0.68      0.72      0.60      2089\n",
      "weighted avg       0.82      0.61      0.62      2089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "preds = clf.predict(X_val)\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_val, preds, average=\"binary\")\n",
    "\n",
    "metrics = {\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'fscore': fscore\n",
    "}\n",
    "\n",
    "print(classification_report(y_val, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f4e50",
   "metadata": {},
   "source": [
    "### Register model\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where we can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints.\n",
    "\n",
    "Let's connect to the model registry using the [HSML library](https://docs.hopsworks.ai/machine-learning-api/latest) from Hopsworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a184969a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsml\n",
    "\n",
    "conn = hsml.connection()\n",
    "mr = conn.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae32238",
   "metadata": {},
   "source": [
    "Before registering the model we will export it as a pickle file using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b41314d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c96062",
   "metadata": {},
   "source": [
    "The model needs to be set up with a [Model Schema](https://docs.hopsworks.ai/machine-learning-api/latest/generated/model_schema/), which describes the inputs and outputs for a model.\n",
    "\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82608e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_schema': {'columnar_schema': [{'name': 'gender', 'type': 'int64'},\n",
       "   {'name': 'seniorcitizen', 'type': 'int64'},\n",
       "   {'name': 'partner', 'type': 'int64'},\n",
       "   {'name': 'dependents', 'type': 'int64'},\n",
       "   {'name': 'tenure', 'type': 'float64'},\n",
       "   {'name': 'phoneservice', 'type': 'int64'},\n",
       "   {'name': 'multiplelines', 'type': 'int64'},\n",
       "   {'name': 'internetservice', 'type': 'int64'},\n",
       "   {'name': 'onlinesecurity', 'type': 'int64'},\n",
       "   {'name': 'onlinebackup', 'type': 'int64'},\n",
       "   {'name': 'deviceprotection', 'type': 'int64'},\n",
       "   {'name': 'techsupport', 'type': 'int64'},\n",
       "   {'name': 'streamingtv', 'type': 'int64'},\n",
       "   {'name': 'streamingmovies', 'type': 'int64'},\n",
       "   {'name': 'contract', 'type': 'int64'},\n",
       "   {'name': 'paperlessbilling', 'type': 'int64'},\n",
       "   {'name': 'paymentmethod', 'type': 'int64'},\n",
       "   {'name': 'monthlycharges', 'type': 'float64'},\n",
       "   {'name': 'totalcharges', 'type': 'float64'}]},\n",
       " 'output_schema': {'columnar_schema': [{'name': 'churn', 'type': 'int64'}]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390c2aa",
   "metadata": {},
   "source": [
    "With the schema in place, we can finally register our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4982eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effc6d1b49d14b12a50358c7591b1694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exported model churn_tutorial_model with version 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'churn_tutorial_model', version: 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mr.sklearn.create_model(\n",
    "    name=\"churn_tutorial_model\",\n",
    "    metrics=metrics,\n",
    "    description=f\"Random forest model trained with {n_estimators} trees.\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema\n",
    ")\n",
    "\n",
    "model.save('model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d3896",
   "metadata": {},
   "source": [
    "Here we have also saved an input example from the training data, which can be helpful for test purposes.\n",
    "\n",
    "It's important to know that every time you save a model with the same name, a new version of the model will be saved, so nothing will be overwritten. In this way, you can compare several versions of the same model - or create a model with a new name, if you prefer that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf756e",
   "metadata": {},
   "source": [
    "#### Finding the best performing model\n",
    "\n",
    "Let's imagine you have trained and registered several versions of the same model. Now you can query the model registry for the best model according to your preferred criterion, say F1-score in our case.\n",
    "\n",
    "The `direction` option is used to indicate if the metric should be high or low (max or min); in our case, it should be high (max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c1e7032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'churn_tutorial_model_1',\n",
       " 'experimentId': None,\n",
       " 'projectName': 'churn',\n",
       " 'experimentProjectName': 'churn',\n",
       " 'name': 'churn_tutorial_model',\n",
       " 'modelSchema': {'href': 'https://hopsworks.glassfish.service.consul:8182/hopsworks-api/api/project/128/dataset/Projects/churn/Models/churn_tutorial_model/1/model_schema.json',\n",
       "  'zip_state': 'NONE'},\n",
       " 'version': 1,\n",
       " 'description': 'Random forest model trained with 89 trees.',\n",
       " 'inputExample': {'href': 'https://hopsworks.glassfish.service.consul:8182/hopsworks-api/api/project/128/dataset/Projects/churn/Models/churn_tutorial_model/1/input_example.json',\n",
       "  'zip_state': 'NONE'},\n",
       " 'framework': 'SKLEARN',\n",
       " 'metrics': {'precision': '0.3887605850654349',\n",
       "  'recall': '0.9474671669793621',\n",
       "  'fscore': '0.5513100436681223'},\n",
       " 'trainingDataset': None,\n",
       " 'environment': ['/Projects/churn/Models/churn_tutorial_model/1/environment.yml'],\n",
       " 'program': 'Models/churn_tutorial_model/1/program.ipynb'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = mr.get_best_model(name=\"churn_tutorial_model\", metric=\"fscore\", direction=\"max\")\n",
    "best_model.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72eae0a",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll look at model serving for the model we just registered to the Model Registry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
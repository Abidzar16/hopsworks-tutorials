{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbdfd41",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Maggy\n",
    "\n",
    "*Note: currently this notebook needs to be run with a PySpark kernel to work properly!*\n",
    "\n",
    "In this notebook, we'll use the [Maggy](https://maggy.ai/master/) library from Hopsworks to run experiments with hyperparameter tuning. In particular we will:\n",
    "\n",
    "- Load a training dataset from the feature store.\n",
    "- Train models on the dataset using different hyperparameters.\n",
    "\n",
    "![tutorial-flow](images/maggy_hp.png)\n",
    "\n",
    "We will train our model using standard Python and Scikit-learn, although it could just as well be trained with other machine learning frameworks such as PySpark, TensorFlow, and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5847a",
   "metadata": {},
   "source": [
    "### Load Training Data\n",
    "\n",
    "First, we'll need to fetch the training dataset that we created in the previous notebook. Since we're running this notebook in a PySpark Kernel we'll get Spark Dataframes, which we'll need to convert back to Pandas Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = fs.get_training_dataset(\"churn_dataset_splitted\")\n",
    "X_train = td.read(\"train\").toPandas()\n",
    "X_val = td.read(\"validation\").toPandas()\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4289c2",
   "metadata": {},
   "source": [
    "Next, we'll one-hot encode the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93adbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_features = [\n",
    "    \"MultipleLines\", \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\",\n",
    "    \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n",
    "    \"Contract\", \"PaymentMethod\"]\n",
    "categorical_features = [s.lower() for s in categorical_features]\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "one_hot_train = pd.DataFrame(enc.fit_transform(X_train[categorical_features]))\n",
    "one_hot_val = pd.DataFrame(enc.transform(X_val[categorical_features]))\n",
    "X_train = pd.concat([X_train.drop(columns=categorical_features), one_hot_train], axis=1)\n",
    "X_val = pd.concat([X_val.drop(columns=categorical_features), one_hot_val], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24436cd",
   "metadata": {},
   "source": [
    "We will train a model to predict `churn` given the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = td.label[0] # \"churn\"\n",
    "\n",
    "y_train = X_train.pop(target)\n",
    "y_val = X_val.pop(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84b1d0",
   "metadata": {},
   "source": [
    "Let's check the distribution of our target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4895016",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4c99e",
   "metadata": {},
   "source": [
    "We can see that the distribution is unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf4de6",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "In the following example, we'll use a random forest ensemble model and do a hyperparameter search over the number of trees in the ensemble (`n_estimators`). Since our dataset is unbalanced we will evaluate each hyperparameter configuration using the *F1-score* rather than *accuracy*.\n",
    "\n",
    "First, we define a training function that will return an evaluation score given a hyperparameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dfa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def training_function(n_estimators):\n",
    "    clf = RandomForestClassifier(class_weight=\"balanced\", n_estimators=n_estimators)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_val)\n",
    "    score = f1_score(y_val, preds)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7280aa",
   "metadata": {},
   "source": [
    "Note that this code assumes that the `X_train`, `y_train` etc variables already exist in the namespace.\n",
    "\n",
    "Let's test the code to see that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003829ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = training_function(1)\n",
    "print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15a2dc",
   "metadata": {},
   "source": [
    "Now let's see if we can find a value for `n_estimators` that gives us a better score.\n",
    "\n",
    "To do this we'll define a search space, which represents the set of possible values we want to consider for our hyperparameters. We'll also need to define datatypes for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8028b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maggy import Searchspace\n",
    "\n",
    "sp = Searchspace(n_estimators=('INTEGER', [1, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40490d",
   "metadata": {},
   "source": [
    "Next we'll define a configuration for our hyperparameter search. Some important parameters are:\n",
    "- `num_trials`: Number of models to train. You should set this based on how much time you are willing to spend. We'll just do five trials here to showcase the functionality.\n",
    "- `optimizer`: Strategy used to determine the next parameter value to try. We will just use grid search, but you can read about alternatives [here](https://maggy.ai/master/hpo/strategies/).\n",
    "- `direction`: Should be set to `max` if the output of `train_fn` should be maximized, otherwise `min`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d69a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maggy.experiment_config import OptimizationConfig\n",
    "\n",
    "config = OptimizationConfig(\n",
    "    searchspace=sp,\n",
    "    optimizer='randomsearch', # TODO use gridsearch instead?\n",
    "    direction='max',\n",
    "    num_trials=5,\n",
    "    name='fraud_lr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16707561",
   "metadata": {},
   "source": [
    "Now we can run the `lagom` method, which tries to find the best value. Lagom is a Swedish word that means \"just right\". The function is \"lagom\" in the way it uses your resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c798b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maggy import experiment\n",
    "\n",
    "result = experiment.lagom(train_fn=training_function, config=config)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be62a0a4",
   "metadata": {},
   "source": [
    "The function returns a dict with results from our experiment. Of special interest is of course the `best_config` dict, which contains the best hyperparameters found. Let's save this dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a40167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"best_params.pickle\", \"wb\") as f:\n",
    "    pickle.dump(result[\"best_config\"], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25877e52",
   "metadata": {},
   "source": [
    "You can also upload this file to your cluster using the *hopsworks* library. To do this you would run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c31b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "hopsworks_conn = hopsworks.connection()\n",
    "project = hopsworks_conn.get_project()\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"best_params.pickle\", \"Resources\")\n",
    "print(uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a25f21",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll look at how to register a model to the [Hopsworks Model Registry](https://docs.hopsworks.ai/machine-learning-api/latest), which enables us to version control our models and easily create APIs for them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

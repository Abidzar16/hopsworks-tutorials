{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb619d4",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Maggy\n",
    "\n",
    "*Note: currently this notebook needs to be run with a PySpark kernel to work properly!*\n",
    "\n",
    "In this notebook, we'll use the [Maggy](https://maggy.ai/master/) library from Hopsworks to run experiments with hyperparameter tuning. In particular we will:\n",
    "\n",
    "- Load a training dataset from the feature store.\n",
    "- Train models on the dataset using different hyperparameters.\n",
    "\n",
    "![tutorial-flow](images/maggy_hp.png)\n",
    "\n",
    "We will train our model using standard Python and Scikit-learn, although it could just as well be trained with other machine learning frameworks such as PySpark, TensorFlow, and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d7e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>31</td><td>application_1653473648291_0132</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://ip-172-31-17-208.eu-north-1.compute.internal:8089/proxy/application_1653473648291_0132/\">Link</a></td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://ip-172-31-16-76.eu-north-1.compute.internal:8044/node/containerlogs/container_e01_1653473648291_0132_01_000001/churn__davit000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aedd8d",
   "metadata": {},
   "source": [
    "### Load Training Data\n",
    "\n",
    "First, we'll need to fetch the training dataset that we created in the previous notebook. Since we're running this notebook in a PySpark Kernel we'll get Spark Dataframes, which we'll need to convert back to Pandas Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc4eca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  seniorcitizen  partner  ...  monthlycharges  totalcharges  churn\n",
      "0       0              0        0  ...        0.069652      0.002907      0\n",
      "1       0              0        0  ...        0.063184      0.002833      1\n",
      "2       0              0        0  ...        0.061194      0.002810      0\n",
      "3       0              0        0  ...        0.066169      0.002867      0\n",
      "4       0              0        0  ...        0.068159      0.002890      1\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "UserWarning: Training dataset splits were defined but no `train_split` (the name of the split that is going to be used for training) was provided. Setting this property to `train`. The statistics of this split will be used for transformation functions."
     ]
    }
   ],
   "source": [
    "feature_view = fs.get_feature_view(\"churn_feature_view\", 1)\n",
    "\n",
    "td_version = 1 \n",
    "_, td_df_random = feature_view.get_training_dataset_splits({'train': 70, 'validation': 30}, version = td_version)\n",
    "\n",
    "X_train = td_df_random[\"train\"].toPandas()\n",
    "X_val = td_df_random[\"validation\"].toPandas()\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f66b43",
   "metadata": {},
   "source": [
    "Next, we'll one-hot encode the categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e404717",
   "metadata": {},
   "source": [
    "We will train a model to predict `churn` given the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b50f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = feature_view.label[0]\n",
    "\n",
    "y_train = X_train.pop(target)\n",
    "y_val = X_val.pop(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63e5c0",
   "metadata": {},
   "source": [
    "Let's check the distribution of our target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af5938d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.730319\n",
      "1    0.269681\n",
      "Name: churn, dtype: float64"
     ]
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dafd2e8",
   "metadata": {},
   "source": [
    "We can see that the distribution is unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668ccc0",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "In the following example, we'll use a random forest ensemble model and do a hyperparameter search over the number of trees in the ensemble (`n_estimators`). Since our dataset is unbalanced we will evaluate each hyperparameter configuration using the *F1-score* rather than *accuracy*.\n",
    "\n",
    "First, we define a training function that will return an evaluation score given a hyperparameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b2c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def training_function(n_estimators):\n",
    "    clf = RandomForestClassifier(class_weight=\"balanced\", n_estimators=n_estimators)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_val)\n",
    "    score = f1_score(y_val, preds)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2b36a",
   "metadata": {},
   "source": [
    "Note that this code assumes that the `X_train`, `y_train` etc variables already exist in the namespace.\n",
    "\n",
    "Let's test the code to see that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc37cbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4953271028037383"
     ]
    }
   ],
   "source": [
    "score = training_function(1)\n",
    "print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b9cb6",
   "metadata": {},
   "source": [
    "Now let's see if we can find a value for `n_estimators` that gives us a better score.\n",
    "\n",
    "To do this we'll define a search space, which represents the set of possible values we want to consider for our hyperparameters. We'll also need to define datatypes for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8a860b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter added: n_estimators"
     ]
    }
   ],
   "source": [
    "from maggy import Searchspace\n",
    "\n",
    "sp = Searchspace(n_estimators=('INTEGER', [1, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f016c",
   "metadata": {},
   "source": [
    "Next we'll define a configuration for our hyperparameter search. Some important parameters are:\n",
    "- `num_trials`: Number of models to train. You should set this based on how much time you are willing to spend. We'll just do five trials here to showcase the functionality.\n",
    "- `optimizer`: Strategy used to determine the next parameter value to try. We will just use grid search, but you can read about alternatives [here](https://maggy.ai/master/hpo/strategies/).\n",
    "- `direction`: Should be set to `max` if the output of `train_fn` should be maximized, otherwise `min`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23378aa2",
   "metadata": {},
   "source": [
    "Now we can run the `lagom` method, which tries to find the best value. Lagom is a Swedish word that means \"just right\". The function is \"lagom\" in the way it uses your resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0d04445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e0d2e102b942b8bdf99054cbc7e008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Maggy experiment', max=2.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Maggy Experiment: churn_lr, application_1653473648291_0132, run 1\n",
      "\n",
      "------ RandomSearch Results ------ direction(max) \n",
      "BEST combination {\"n_estimators\": 89} -- metric 0.5510835913312694\n",
      "WORST combination {\"n_estimators\": 30} -- metric 0.5309548793284364\n",
      "AVERAGE metric -- 0.5410192353298529\n",
      "EARLY STOPPED Trials -- 0\n",
      "Total job time 0 hours, 0 minutes, 25 seconds\n",
      "\n",
      "Finished Experiment\n",
      "{'best_id': 'faa7f5aad3e410ec', 'best_val': 0.5510835913312694, 'best_hp': {'n_estimators': 89}, 'worst_id': 'a71a06c8d311c21f', 'worst_val': 0.5309548793284364, 'worst_hp': {'n_estimators': 30}, 'avg': 0.5410192353298529, 'metric_list': [0.5510835913312694, 0.5309548793284364], 'num_trials': 2, 'early_stopped': 0}\n"
     ]
    }
   ],
   "source": [
    "from maggy import experiment\n",
    "result = experiment.lagom(train_fn=training_function, \n",
    "                          searchspace=sp,\n",
    "                          optimizer='randomsearch', \n",
    "                          direction='max',\n",
    "                          num_trials=2,\n",
    "                          name='churn_lr')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace6a4d2",
   "metadata": {},
   "source": [
    "The function returns a dict with results from our experiment. Of special interest is of course the `best_config` dict, which contains the best hyperparameters found. Let's save this dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da3f9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"best_params.pickle\", \"wb\") as f:\n",
    "    pickle.dump(result[\"best_hp\"], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9604c3",
   "metadata": {},
   "source": [
    "You can also upload this file to your cluster using the *hopsworks* library. To do this you would run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98da20eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Resources/best_params.pickle\n",
      "Uploading: 100.000%|##########| 32/32 elapsed<00:00 remaining<00:00"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "hopsworks_conn = hopsworks.connection()\n",
    "project = hopsworks_conn.get_project()\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"best_params.pickle\", \"Resources\")\n",
    "print(uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eecc6",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll look at how to register a model to the [Hopsworks Model Registry](https://docs.hopsworks.ai/machine-learning-api/latest), which enables us to version control our models and easily create APIs for them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1dc5e4d",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Model training & UI Exploration</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">In this last notebook, we will train a model on the dataset we created in the previous tutorial. We will train our model using standard Python and Scikit-learn, although it could just as well be trained with other machine learning frameworks such as PySpark, TensorFlow, and PyTorch. We will also show some of the exploration that can be done in Hopsworks, notably the search functions and the lineage. </span>\n",
    "\n",
    "## **üóíÔ∏è This notebook is divided in 3 main sections:** \n",
    "1. **Loading the training data**\n",
    "2. **Train the model**\n",
    "3. **Explore feature groups and views** via the UI.\n",
    "\n",
    "![tutorial-flow](images/03_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ce23be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "conn = hsfs.connection()\n",
    "fs = conn.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af65e46",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> ‚ú® Load Training Data </span>\n",
    "\n",
    "First, we'll need to fetch the training dataset that we created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa79c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Training dataset splits were defined but no `train_split` (the name of the split that is going to be used for training) was provided. Setting this property to `train`. The statistics of this split will be used for transformation functions.\n",
      "FutureWarning: pyarrow.hdfs.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load data.\n",
    "feature_view = fs.get_feature_view(\"transactions_view\", 1)\n",
    "_, td_df = feature_view.get_training_dataset_splits({'train': 80, 'validation': 20}, start_time=None, end_time=None, version = 1)\n",
    "\n",
    "td = fs.get_training_dataset(\"transactions_view_1\",1)\n",
    "X_train = td_df[\"train\"]\n",
    "X_val = td_df['validation']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29f5895",
   "metadata": {},
   "source": [
    "We will train a model to predict `fraud_label` given the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa6ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target feature from input features.\n",
    "target = target = feature_view.label[0]  \n",
    "y_train = X_train.pop(target)\n",
    "y_val = X_val.pop(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d8bba",
   "metadata": {},
   "source": [
    "Let's check the distribution of our target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219b3b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998526\n",
       "1    0.001474\n",
       "Name: fraud_label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fafadf",
   "metadata": {},
   "source": [
    "Notice that the distribution is extremely skewed, which is natural considering that fraudulent transactions make up a tiny part of all transactions. Thus we should somehow address the class imbalance. There are many approaches for this, such as weighting the loss function, over- or undersampling, creating synthetic data, or modifying the decision threshold. In this example, we'll use the simplest method which is to just supply a class weight parameter to our learning algorithm. The class weight will affect how much importance is attached to each class, which in our case means that higher importance will be placed on positive (fraudulent) samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2089b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üèÉ Train Model</span>\n",
    "\n",
    "Next we'll train a model. Here, we set the class weight of the positive class to be twice as big as the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7ae6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 0.09999999999999998, 1: 0.9},\n",
       "                   dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "                   l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                   penalty='l2', random_state=None, solver='liblinear',\n",
       "                   tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model.\n",
    "pos_class_weight = 0.9\n",
    "clf = LogisticRegression(class_weight={0: 1.0 - pos_class_weight, 1: pos_class_weight}, solver='liblinear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268b845",
   "metadata": {},
   "source": [
    "Let's see how well it performs on our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b43fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     21214\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           1.00     21244\n",
      "   macro avg       0.50      0.50      0.50     21244\n",
      "weighted avg       1.00      1.00      1.00     21244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = clf.predict(X_val)\n",
    "\n",
    "print(classification_report(y_val, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb2fa2",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üëì  Exploration</span>\n",
    "In the Hopsworks feature store, the metadata allows for multiple levels of explorations and review. Here we will show a few of those capacities. \n",
    "\n",
    "### üîé <b>Search</b> \n",
    "Using the search function in the ui, you can query any aspect of the feature groups and training data that was previously created. In the gif below we show how the tag we added in the first section can be searched to get all the feature groups with the `PII` tag value.\n",
    "\n",
    "### üìä <b>Statistics</b> \n",
    "We can also enable statistics in one or all the feature groups here we commented the command so that it wouldnt run for too long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29501a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans_fg = fs.get_feature_group()\n",
    "#trans_fg.update_statistics_config(\n",
    "#       enabled=True, \n",
    "#       correlations=False, \n",
    "#       histograms=False, \n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb36bdb",
   "metadata": {},
   "source": [
    "\n",
    "### ‚õìÔ∏è <b> Lineage </b> \n",
    "In all the feature groups and feature view you can look at the relation between each abstractions; what feature group created which training dataset and that is used in which model.\n",
    "This allows for a clear undestanding of the pipeline in relation to each element. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af62783",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üéÅ  Wrapping things up </span>\n",
    "\n",
    "We have now performed a simple training with training data that we have created in the feature store. This concludes the fisrt module and introduction to the core aspect of the feauture store. In the second module we will introduce streaming and external feature groups for a similar fraud use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
